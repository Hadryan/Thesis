\vspace{-5pt}
\samenvatting
\vspace{-35pt}
% \begin{flushright} 
% \textbf{Leren met imperfect toezicht voor taalbegrip} 
% \textbf{Leren met imperfecte supervisie voor taalbegrip} 
\textbf{Leren met Imperfecte Supervisie om Taal te Begrijpen}
% \end{flushright}
\vspace{-12pt}\par\noindent\rule{\textwidth}{0.4pt}
Mensen leren complexe problemen op te lossen en onderliggende concepten en relaties te ontdekken op basis van beperkte, ruizige of inconsistente observaties en kunnen daarmee succesvol generaliseren.
Dit berust grotendeels op het argument van \emph{de armoede van de stimulus}, ofwel \emph{het probleem van Plato}: ``Hoe weten we zoveel wanneer het beschikbare bewijs zo mager is?''

\vspace{-1pt}
Daarentegen is het succes van machine leren vaak sterk gecorreleerd met de hoeveelheid beschikbare hoge kwaliteit, gelabelde data. Machine leren met beperkt gelabelde data of met \emph{imperfecte supervisie} blijft een belangrijke uitdaging.
In de praktijk is echter vaak geen grote hoeveelheid gelabelde data van hoge kwaliteit beschikbaar.
Hierdoor ontstaat een toenemende behoefte om modellen te ontwerpen die complexe taken met imperfecte supervisie kunnen oplossen, oftewel waarbij het leerproces op imperfect gelabelde data is gebaseerd.

Bij het ontwerpen van algoritmen lijken methodes die enkel op basis van eerdere ervaringen leren geen generaliserende oplossingen op te leveren.
Net als bij menselijk leren, waarbij een deel van de kennis van nature aanwezig is, kunnen ook leeralgoritmen mogelijk beter generaliseren wanneer een deel van de kennis gecodeerd wordt in het algoritme in de vorm van voorkennis.

\vspace{-1pt}
In dit proefschrift richten we ons op \textbf{het probleem van de armoede van de stimulus voor machine leren}.
Wij stellen dat zelfs beperkte, ruizige signalen nuttige informatie kunnen bevatten.
Zulke signalen kunnen, samen met voorkennis die wordt gecodeerd in de algoritmen, gebruikt worden om complexe problemen op te lossen.
We verbeteren het leerproces met imperfecte supervisie door (i) \emph{voorkennis in leeralgoritmen toe te passen}, (ii) \emph{data kunstmatig aan te vullen en te leren hoe de data beter te gebruiken is}, en (iii) \emph{inductieve bias in de leeralgoritmen te introduceren}.
Deze algemene ideeën zijn in feite de belangrijkste ingrediënten voor het bouwen van leeralgoritmen die beter kunnen generaliseren bij beperkt gelabelde data.

\vspace{-1pt}
We concentreren ons op het begrijpen van en redeneren met taal, \'e\'en van de unieke cognitieve vaardigheden van de mens en een cruciaal probleem in de kunstmatige intelligentie.
We proberen het leerproces te verbeteren op principiële manieren die ad-hoc en domein- of taakspecifieke trucs vermijden.
We onderzoeken onze ideeën aan de hand van een breed scala van taken zoals het modelleren van sequenties en taalbegrip.