\section{Related Work}
In this section, we discuss related studies to the applications that we evaluated \acswlm on, i.e in feedback in the retrieval task and grop profiling in contextual suggestion. 

\subsection{Relevance Feedback}
First, we talk about different feedback approaches in particular methods in the language modeling framework. Then, after discussing initiatives focusing on the task of TRF and PRF, we will discuss the main challenges of this tasks and some already proposed methods which address them.

It has been shown that there is a limitation on providing increasingly better results for retrieval systems only based on the original query~\citep{Rijsbergen:1986}. So, it is crucial to reformulate the search request using terms which reflect the user's information need to improve the performance of the retrieval systems. 
To address this issue, automatic feedback methods for information retrieval were introduced fifty years ago~\citep{Rocchio:1971} and have been extensively studied  during past decades.
%~\citep{Rijsbergen:1981,Robertson:1976,Salton:1985,Robertson:1991,Harman:1992,Buckley:1994,Lavrenko:2001,Zhai:SMM:2001,Ruthven:2003,Tao:2006, He:2009:ECIR,Lv:2009,He:2009:CIKM,Harman:2009,Carpineto:2012,Lv:2014}. 
As the earliest relevance feedback approach in information retrieval, the Rocchio method~\citep{Rocchio:1971} is proposed in the vector processing environments for changing the query vector to be similar to the relevant documents vectors and dissimilar to the non-relevant documents vectors. 
Later, probabilistic methods were proposed to select expansion terms from feedback documents based on a term weighting approach~\citep{Robertson:1976,Rijsbergen:1981}. With the development of language models, several feedback approaches have been proposed in this framework to improve the query language model~\citep{Zhai:SMM:2001,Tao:2006,Lavrenko:2001,Hiemstra:2004,Lv:2014}. 
The mixture model~\citep{Zhai:SMM:2001}, is one of the well-known feedback methods in the language modeling framework which empirically performs well. The idea is to extract a discriminative language model of feedback documents by decreasing weights of the background terms. 
As an extension to this model, the regularized mixture model has been proposed by \citet{Tao:2006} which not only involves the query model in the estimated feedback model but also has document-specific mixing coefficients to let different documents have a different amount of background terms.

In the relevance model (RM)~\citep{Abdul-jaleel:2004,Lavrenko:2001} given the query, a model is estimated as a multinomial distribution over terms that indicates the likelihood of each term given the query as the evidence, based on the occurrences of term together with the query terms in the feedback documents.  In a comparable study conducted by~\citet{Zhai:SMM:2001}, it has been shown that RM3 as a variant of the relevance model is one of the best performing methods which is strongly robust.
Divergence minimization~\citep{Zhai:SMM:2001} is also one of the feedback approaches in the language modeling framework which tries to estimate a feedback model which is close to the language model of every feedback document but far from the collection language model as an approximation of the non-relevant language model. This method generates a highly skewed feedback model which makes it unable to perform well. Recently, \citet{Lv:2014} proposed the maximum-entropy divergence minimization model that, by adding an entropy term, regularizes the original divergence minimization model leading to significant improvements in the performance of the original method.

Parsimonious language model~\citep{Hiemstra:2004} is one of the models employed for feedback~\citep{Meij:2008,Hiemstra:2008:TREC,Kaptein:2008:TREC}. Generally, it tries to describe the feedback model using fewer number of parameters and similar to the mixture model, the common words in the collection are removed from the model in the estimation process which leads to a more lean and mean language model.  \citet{Zamani:2016a} considering the feedback problem as a recommendation problem, made use of matrix factorization in order for predicting expansion terms in a weighted manner.

Besides the ad hoc studies, there have been some initiatives with the aim of investigation and study the problem of (pseudo-)relevance feedback in detail. In 2003, Reliable Information Access (RIA) Workshop~\citep{Harman:2009,Warren:2004} 
%,Gu:2004:RIA,Montgomery:2004,Lynam:2004:RIA,Terra:2005
was organized with the goal of understanding the contributions of both system variability factors and topic variability factors to the overall retrieval variability in feedback. 
Later on in 2008, the Relevance Feedback track was intended as one the TREC tracks and it has been continued for two more years. The initial goal of the TREC Relevance Feedback track was evaluating and comparing different feedback methods~\citep{Buckley:2008:TREC}. In the next years, besides the comparison of different methods, they tried to investigate some properties of documents and how they affect the relevance feedback performance. More precisely, the tasks focus on studying the notion of what is a good document for relevance feedback and how a system can recognize a good document~\citep{Buckley:2010:TREC}. 
In addition to the Relevance Feedback track, the Robust track in TREC defined one of the goals to improve the consistency of feedback systems by focusing on the poorly performing topics~\citep{Voorhees:2003:TREC}.

Applying feedback deteriorates the performance of retrieval in some topics, especially in pseudo relevance feedback in which the performance of the feedback run strongly depends on the quality of the top documents in the initial run~\citep{Harman:2009,Collins-Thompson:2009}. 
%,Billerbeck:2003
On the other hand, using some documents (even relevant documents) might harm the feedback performance~\citep{Terra:2005,Lv:2009:CIKM}.  
Hence, there are some challenges in the feedback problem like how to determine whether applying the feedback improves the performance for a specific topic, and how to measure the quality of each feedback document and how to incorporate this information in the feedback process.
%
\citet{He:2009:CIKM} proposed to examine the interests of feedback documents to the query topic using Entropy, which estimates the distribution of query terms in the feedback documents to see to which degree the feedback documents are interested in the topic.  In other work~\citep{He:2009:ECIR} they try to detect good feedback documents in PRF by grouping documents employing some features like the probability of the query terms in the feedback document, the similarity of each feedback documents with other feedback documents, and closeness of expansion terms to the regional query terms. 
%\citet{Lee:2008} proposed to find the dominant documents from the initial run as better documents for PRF\@. 
\citet{Tao:2004} proposed a two-stage mixture model in which taking the query as a relevant prior, feedback documents are divided into relevant and background documents and only the documents in the relevant group are employed for updating the query model. 
\citet{Collins-Thompson:2007} tried to model feedback uncertainty to improve the robustness. They proposed to perform sampling over the feedback documents as well as the query to generate different sets of feedback documents and several query variants. Then, combining different feedback models from alternative sets, the robustness of the feedback model can be  improved.

\medskip
Arguably, the key issue in the feedback is robustness in terms of being able to deal with non-relevant terms from non-relevant or partially relevant documents. \acswlm addresses the robustness problem head on. This is achieved by using the information from the collection and other feedback documents to control the contribution of documents in the feedback model regarding their merit, and to avoid the selection of non-relevant expansion terms.

\subsection{Group profiling for Content Customization}
Group profiling can help understand both explicit groups, like Facebook groups, and implicit groups, like groups extracted by community detection algorithms. There is a wide range of applications for group profiling, like understanding social structures~\citep{Tang:2011}, network visualization, recommender systems~\citep{Hu:2014,Shang:2014,Amer-Yahia}, and direct marketing~\citep{Custers:2003}. 

There is various research done on the task of group profiling which, given the individual attributes and preferences, aims to find out group-level shared preferences~\cite{Senot:2011,Masthoff:2011}.
\citet{Tang:2011} presented three different methods for group profiling: \textsl{Aggregation}, which tries to find features that are shared by the whole group; \textsl{Differentiation}, which tries to extract features that can help to differentiate one group from others; and \textsl{Egocentric differentiation}, which tries to extract features that can help to differentiate members of one group from the neighbour members. In recent work, \citet{Hu:2014} proposed a deep-architecture model to learn a high level representation of group preferences.

For group recommendation there is research on building a model of a group by forming a linear combination of the individual models~\citep{Jameson:2007}. Some of them construct the group's preference model on the basis of individual preference models, using a notion of distance between preference models~\citep{Yu:2006}. Some approaches try to divide the group into several categories of homogeneous users and specify the preference model for each subgroup. Then they create the group model as a weighted average of the subgroup models, with the weights reflecting the importance of the subgroups~\citep{Ardissono:2003}.
