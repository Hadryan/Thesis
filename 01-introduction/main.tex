% !TEX root = ../thesis_main.tex
\chapter{Introduction}


This is considered as a part of the bigger effort to democratize AI by making it dramatically easier to build AI-powered applications in all domains



http://jmlr.org/papers/volume17/gulchere16a/gulchere16a.pdf.

Strong prior knowledge (inductive bias).
How does background knowledge guide learning from sparsely observed data? 
What form does the knowledge take, across different domains and tasks?
How is that knowledge itself learned? 


Learning from weakly annotated examples is an increasingly popular approaches for addressing the labeled data scarcity in many tasks and applications. 
Weak supervision is usually refers to higher-level approaches to labele training data that are cheaper and/or more efficient, such as:
\begin{itemize}
    \item distant or heuristic supervision,
    \item incidental signals that  exist in the data and the environment, independently of the tasks and they are co-related to the target tasks.
    \item supervising by specifying constraints that should hold over the output space,
    \item using noisy labels, 
    \item pool limited supervision signal by using multi-task learning,
    \item data augmentation strategies to express class invariances,
    \item introduction of other forms of structured prior knowledge.
\end{itemize}
An overarching goal of such approaches is to use domain knowledge and data resources provided by subject matter experts, but to solicit it in higher-level, lower-fidelity, or more opportunistic ways.

can be exploited, along with appropriate algorithmic support, to provide sufficient supervision and facilitate learning


https://medium.com/center-for-data-science/neural-networks-and-toddlers-how-learning-biases-can-improve-word-learning-56e477dc1ee3


\url{https://www.princeton.edu/~nivlab/papers/GershmanNiv_inpress.pdf}

% \resq{C2.1}

