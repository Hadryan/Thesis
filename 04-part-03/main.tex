% !TEX root = ../thesis-main.tex
\part{Injecting Inductive Biases for Data Efficiency}
\label{part3}
pertain to the space of internal models considered by a learner, and they help the learner make inferences
that go beyond the observed data.

Any basis for choosing one generalization
over another, other than strict consistency with the
observed training instances 


The idea of weight sharing, we can save massively on the number of parameters that we are training. Less parameters means learn faster with fewer data points. 

If you learn a transformation which 


an inductive bias of a learner is the set of additional assumptions sufficient to justify its inductive inferences as deductive inferences.


 inject more inductive bias that leads to significant gains in terms of data efficiency.
 
 
 data often has certain symmetries: Convolutions
If there is symmetry in the input space, exploit it.
The most canonical example for exploiting such symmetry are convolutional neural networks, which are \emph{translation invariant}. Invariance in general means that an object is recognized as an object even if its appearance varies in some way. 


\input{04-part-03/chapter-06/main.tex}
