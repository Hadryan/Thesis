\begin{table}[t!]
\centering
\caption{Average error and number of failed tasks ($> 5\%$ error) out of 20 (in parentheses; lower is better in both cases) on the bAbI dataset under the different training/evaluation setups. We indicate state-of-the-art where available for each, or `-' otherwise.}
\label{tab:babi-results}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{lllll}
& & & & \\ \toprule
\multirow{2}{*}{ \bf Model } & \multicolumn{2}{c}{ \bf 10K samples } & \multicolumn{2}{c}{ \bf 1K samples } \\ \cmidrule{2-5}
& \textit{train single} & \textit{train joint} & \textit{train single} & \textit{train joint} \\ \midrule
\multicolumn{5}{c}{\bf Previous best results:} \\ \midrule
\bf QRNet~\citep{seo2016query} & 0.3 (0/20) & - & - & - \\
\bf Sparse DNC~\citep{rae2016scaling} & - & 2.9 (1/20) & - & - \\
\bf GA+MAGE~\cite{dhingra2017linguistic} & - & - & 8.7 (5/20) & - \\
\bf MemN2N~\cite{sukhbaatar2015} & - & - & -  & 12.4 (11/20) \\\midrule
\multicolumn{5}{c}{\bf Our results:} \\ \midrule
\bf Transformer~\citep{transformer} & 15.2 (10/20) & 22.1 (12/20) & 21.8 (5/20) & 26.8 (14/20) \\
\bf Universal Transformer (this work) & 0.23 (0/20) & 0.47 (0/20) & 5.31 (5/20) & 8.50 (8/20) \\
\bf UT w/ dynamic halting (this work) & {\bf 0.21 (0/20)} & {\bf 0.29 (0/20)} & {\bf 4.55 (3/20)} & {\bf 7.78 (5/20)} \\ \bottomrule
\end{tabular}
\end{adjustbox}
\end{table}